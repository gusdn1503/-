우리는 머신 러닝을 할 때 항상 눈에 보이지 않는 원리와 이유에 대해 집중해야한다. (갑자기?)
대부분의 머신 러닝 프로그레스는 눈에 보이지 않는 곳에서 자동적으로 진행되기 때문에 그 내면에 깔린
원리를 알지 못하고 편리하게 구축된 API만 쓴다면 그 이상으로 응용해서 나아갈 수 없기 때문이다. 
따라서 앞으로 어떤 기법에 대해서 배울때는 최대한 여러 자료(구글,유튜브 영상자료 등)을 다양한 
시각에서 참고하여 그 내면의 원리를 이해하며 가도록 하겠다.


이번 포스팅에서는 CNN에 대해 알아보자...!

CNN은 고양이가 사물을 인식할때 부분 부분을 따로 인식한 뒤 이것을 합쳐서 인식한 것에서 아이디어를 
따온 NN으로서 상당한 성능을 인정받고 있다. 특히 이미지 인식 분야에서 두드러지는 성능을 발휘한다. 

고양이의 인식처럼 CNN은 부분 부분을 인식한 뒤 합치는 과정을 거치는 데 
원 이미지(ex 32X32X3)을 여러개의 각기 다른 가중치를 지닌 필터(ex 5X5X3)를 통과해서 
한 값을 가져오자는 아이디어이다.
여기서 각 필터들은 사물의 가로 선, 세로 선 등의 특징을 '학습'하게 된다. 
즉. 어떤 사물(ex 사자)의 부분 부분의 모양을 학습하고 후에 같은 사물(사자)를 담은 다른 사진을 보고
그 사진 속에 같은 부분 부분 모양들이 존재한다는 것을 각 학습된 weight들이 동작해 알아내어 
결과적으로 비슷한 부분 부분 들이 많이 있을 수록 그 사물일 확률이 높다고 판명하는 메카니즘이다. 
여담으로 weight들은 처음에는 가로 세로 등의 간단한 모양에서 학습이 진행될 수록 
더 정교한 모양을 인지한다는 주장이 있다. 
그런데 여기서 드는 궁금증은 그러면 어떻게 각각의 필터는 하나의 가중치로 일원화 되지 않고
각 필터마다 다른 부분(가로,세로선)을 포착하는 필터로 다분화 되어 갈까라는 의문이다.
정확한 메카니즘을 알기는 어렵지만 결국 마지막에 Fully-connected layer가 존재하기 때문에

이때 필터를 움직이는 픽셀 단위를 stride라고 한다. (N-f)/stride+1
그런데 이렇게 한번씩 필터를 통과해서 나올 때 마다 우리는 원 이미지보다 더 작은 이미지를 얻게 된다.(28*28*3)
이런 정보 손실을 막기 위해서 padding이라고 원 이미지 주변에 0 값으로 된 픽셀들을 깔아주는 작업을 한다. 
이 패딩을 하고 나면 원 이미지와 같은 크기를 output으로 받을 수 있고,
원 이미지의 경계를 나타내는 역할을 해주는 등 여러 장점이 존재한다.

그런데 










