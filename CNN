우리는 머신 러닝을 할 때 항상 눈에 보이지 않는 원리와 이유에 대해 집중해야한다. (갑자기?)
대부분의 머신 러닝 프로그레스는 눈에 보이지 않는 곳에서 자동적으로 진행되기 때문에 그 내면에 깔린
원리를 알지 못하고 편리하게 구축된 API만 쓴다면 그 이상으로 응용해서 나아갈 수 없기 때문이다. 
따라서 앞으로 어떤 기법에 대해서 배울때는 최대한 여러 자료(구글,유튜브 영상자료 등)을 다양한 
시각에서 참고하여 그 내면의 원리를 이해하며 가도록 하겠다.


이번 포스팅에서는 CNN에 대해 알아보자...!

CNN은 고양이가 사물을 인식할때 부분 부분을 따로 인식한 뒤 이것을 합쳐서 인식한 것에서 아이디어를 
따온 NN으로서 상당한 성능을 인정받고 있다. 특히 이미지 인식 분야에서 두드러지는 성능을 발휘한다. 

고양이의 인식처럼 CNN은 부분 부분을 인식한 뒤 합치는 과정을 거치는 데 
원 이미지(ex 32X32X3)을 여러개의 각기 다른 가중치를 지닌 필터(ex 5X5X3)를 통과해서 
한 값을 가져오자는 아이디어이다.
여기서 각 필터들은 사물의 가로 선, 세로 선 등의 특징을 '학습'하게 된다. 
즉. 어떤 사물(ex 사자)의 부분 부분의 모양을 학습하고 후에 같은 사물(사자)를 담은 다른 사진을 보고
그 사진 속에 같은 부분 부분 모양들이 존재한다는 것을 각 학습된 weight들이 동작해 알아내어 
결과적으로 비슷한 부분 부분 들이 많이 있을 수록 그 사물일 확률이 높다고 판명하는 메카니즘이다.
이때 처음 이미지 말고도 우리가 필터를 여러번 적용해서 만든 activation 맵을 쌓아서 다시 거기에
필터를 적용해서 activation map들을 추출할 수도 있다. -->이 부분의 직관적 이해가 중요할듯.
그런데 이때 이런 convolution layer 층을 늘릴 수록  

여담으로 weight들은 처음에는 가로 세로 등의 간단한 모양에서 학습이 진행될 수록 
더 정교한 모양을 인지한다는 주장이 있다. 
그런데 여기서 드는 궁금증은 그러면 어떻게 각각의 필터는 하나의 가중치로 일원화 되지 않고
각 필터마다 다른 부분(가로,세로선)을 포착하는 필터로 다분화 되어 갈까라는 의문이다.
아마 각 weight들의 초기 점들이 모두 다르기에 그 점과 가까운 minimum들로 각각 학습하는 것이 
아닌가 하는 생각이 있지만 이 부분은 추후 조금 더 알아보자.

이때 필터를 움직이는 픽셀 단위를 stride라고 한다. (N-f)/stride+1의 공식에 따라 output이 결정된다.
그런데 이렇게 한번씩 필터를 통과해서 나올 때 마다 우리는 원 이미지보다 더 작은 이미지를 얻게 된다.(28*28*3)
이런 정보 손실을 막기 위해서 padding이라고 원 이미지 주변에 0 값으로 된 픽셀들을 깔아주는 작업을 한다. 
이 패딩을 하고 나면 원 이미지와 같은 크기를 output으로 받을 수 있고,
원 이미지의 경계를 나타내는 역할을 해주는 등 여러 장점이 존재한다.

이렇게 필터를 거친 activation map에서 pooling이라는 작업을 해주어야한다.
pooling역시 각 필터의 크기를 2*2같이 정해주고 stride도 정해줘야한다.
그런데 보통은 필터를 겹치지 않게 하는 stride를 정해준다. (이 경우는 2이다.)
주로 해당 영역에서 가장 큰 값을 가져오는 max pooling이 자주 사용되기 때문이다.
이 pooling을 하는 이유는 크게 2가지이다. 
1. 이미지의 뒤툴림이나 크기 변화에 따른 왜곡의 영향을 축소
-->이미지가 조금씩 변화할때 pooling을 한 뒤에 각 이미지를 분석하면 변화하는 픽셀 수가 상당히 감소된다. 
2. 사이즈를 줄임으로써 뒤이은 네트워크에 가해지는 부담 경감

일련의 과정이 끝난 다음에는 3*3*10의 activation map을 전부 일렬로 핀다음에 Fully connected layer의 
input으로 넣어서 우리가 원래 하였던 softmax classifcation을 뒤에 덧붙이면 된다.











