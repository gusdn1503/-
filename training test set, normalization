이번에는 training test set을 나누는 방법과 learning rate, normalization에 대해서 알아보겠습니다.
이럴떄 우리가 기존에 쓰던 
x=tf.placeholder("float",[None,3])의 장점이 드러난다. 
그냥 기존과 다 똑같이 하고 prediction accuray 모두 같은 방법으로 한다.
다만 launch 단계에서 sess.run(optimizer(or train),feed_dict=feed_train)으로 하고
prediction,accuracy를 하는 부분에서만
sess.run(prediction,feed_dict=feed_test)하면 되는 것이다....!!


먼저 learning rate에 대해서 알아보면 이것이 너무 크면 overshooting의 우려가 있고 이것이 너무 작으면
우리가 원하는 global minimum으로 가지 않을 우려가 있습니다. 따라서 cost 함수의 모양을 관찰하면서 하는 것이 좋습니다.ㅁ
step 마다 cost를 출력하도록 하면 중간에 갑자기 inf 이나오면서 무서운 Nan이 뜰 수 있습니다.
우리가 주로 쓰는 cross entropy등의 cost function은 모두 log 함수를 활용하기 떄문에 log안에 들어가는 값이
1에서 0으로 변하기만 해도 바로 무한대로 발산하기 때문에 learning rate을 크게 하면 자주 볼 수 있을 것입니다. 
반대로 너무 작게하면 cost가 거의 변하지 않는 양상을 볼 수 있다. 

이번엔 normalization이 왜 필요한지 알아봅시다.
현실세계의 데이터는 항상 아름다운 형태로 되어있는 것이 아니기 때문에 
x1은 1~100 까지인데 x2는 1~50000000 의 큰 수로 형성될 수 있습니다. 
그런데 이 둘을 전처리 하지 않고 그냥 집어넣으면 등고선이 x1 축으로는 좁은데 x2축으로는 매우 넓은 타원형 모양이 형성됩니다.
이런 상황에서 learning rate을 조정하면 x1에 맞추려면 매우 작게해야하고 x2엠 맞추려면 매우 크게해야합니다.
따라서 어느 한쪽에 맞추더라도 다른 쪽에 문제가 나서 overshooting 등이 쉽게 일어나게 되어 크기를 모두 일원화 시켜주는
normalization이 필요한 것입니다. 
코드는 간단하다. 기본 데이터 xy=np.array()형태에 MinMaxScaler(xy)하면 된다. 

우리가 기존의 데이터로 너무 학습을 정교하게 잘시키면 overfitting이 발생할 수 있습니다. 
이는 기존의 데이터에 너무 지나치게 집중해서 그 데이터만을 잘 '설명'할 수 있게 모델이 변한다는 것입니다.
이를 해결하기 위해서는 간단하게는 트레이닝 데이터 수를 늘리는 방법이 있고 
독립 변수 수를 줄이는 방법이 있고 regularization을 하는 방법이 있습니다. 
regularization은 각 weight간의 격차를 줄이자는 의미로도 이해할 수 있습니다. 
우리가 하는 코스토 최소화 loss=1/n*sigma(c.e.c.f)였는데 거기다가 lambda(regularization strength)*sigma(weight^20
이 항을 더하면 각 weight가 커질수록 loss역시 커지고 weight가 작을수록 loss역시 작아지기 때문에
일반적으로 cost를 최적화하는 weight를 찾는 것 외에 weight를 작게 하려는 압력이 들어옵니다. 
따라서 각 weight 간 격차가 줄어들 것입니다.

http://cs231n.github.io/assets/nn1/reg_strengths.jpeg

이 페이지를 참조해보자..! lambda에 따른 변화를 알 수 있다. 
